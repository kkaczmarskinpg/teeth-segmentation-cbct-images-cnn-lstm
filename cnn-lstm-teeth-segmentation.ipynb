{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import metrics\n",
    "import CNNLSTMModel\n",
    "import ConvLSTM2DModel\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "LUCKY_NUMBER = 2\n",
    "TARGET_SIZE = (32, 32) # For no compression choose -1\n",
    "TARGET_SLICES = 304\n",
    "\n",
    "PHOTOS_PATH = \"/run/media/student/DataStorage/images/\"\n",
    "MASK_PATH = \"/run/media/student/DataStorage/masks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPUs Available: \",tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "\n",
    "# Set the policy to mixed precision\n",
    "set_global_policy('mixed_float16')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(LUCKY_NUMBER)\n",
    "batch_size = 2\n",
    "epochs = 10\n",
    "\n",
    "scan_names = [file[:8] for file in os.listdir(PHOTOS_PATH) if file.endswith(\".nii.gz\")]\n",
    "train, val, test = utils.split_train_val_test(scan_names, 0.7, 0.15, 0.15)\n",
    "print(f\"Training data size: {len(train)}, Validation data size: {len(val)}, Test data size: {len(test)}\")\n",
    "\n",
    "print(train)\n",
    "train_gen = utils.cbct_data_generator(PHOTOS_PATH, MASK_PATH, train)\n",
    "val_gen = utils.cbct_data_generator(PHOTOS_PATH, MASK_PATH, val)\n",
    "\n",
    "\n",
    "model = CNNLSTMModel.create_cnn_lstm_model(image_shape=TARGET_SIZE, num_slices=TARGET_SLICES)\n",
    "#model = ConvLSTM2DModel.create_cnn_convlstm2d_model(image_shape=TARGET_SIZE, num_slices=TARGET_SLICES)\n",
    "model.summary()\n",
    "\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[9].input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_gen, \n",
    "    batch_size=2,\n",
    "    steps_per_epoch=len(train)//batch_size,\n",
    "    #validation_data=val_gen,\n",
    "    #validation_steps=len(val),\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scan = utils.load_nifti_cbct_scan(PHOTOS_PATH+train[1]+\"_0000.nii.gz\")\n",
    "test_scan = test_scan[..., np.newaxis]\n",
    "test_scan = np.expand_dims(test_scan, axis=0)\n",
    "\n",
    "predictions = model.predict(test_scan)\n",
    "\n",
    "predicted_mask = predictions[0]\n",
    "\n",
    "binary_mask = (predicted_mask > 0.5).astype(np.float32)\n",
    "\n",
    "print(predicted_mask[200,:,:,0] == predicted_mask[300,:,:,0])\n",
    "\n",
    "plt.imshow(predicted_mask[120, :, :, 0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_index = 100\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title(\"Original Slice\")\n",
    "plt.imshow(test_scan[0, slice_index, :, :, 0], cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title(\"Predicted Mask\")\n",
    "plt.imshow(predicted_mask[slice_index, :, :, 0], cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title(\"Binary Mask\")\n",
    "plt.imshow(binary_mask[slice_index, :, :, 0], cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "\n",
    "original_mask = utils.load_nifti_mask(MASK_PATH+train[1]+\".nii.gz\")\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title(\"Original Mask\")\n",
    "plt.imshow(original_mask[slice_index,:,:], cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
